{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227226903321.75583"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ObjectiveFunctions as of\n",
    "import numpy as np\n",
    "\n",
    "x=np.array([1.2181048,9,35])\n",
    "of.MI_Spring_Obj(x)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitness Convergence\n",
      "[[  1.20765103   9.          35.        ]\n",
      " [  1.65111669   5.          36.        ]\n",
      " [  1.6506413    5.          36.        ]\n",
      " [  1.65059476   5.          36.        ]\n",
      " [  1.64666268   5.          36.        ]\n",
      " [  1.66190089   5.          36.        ]\n",
      " [  1.66379604   5.          36.        ]\n",
      " [  1.17534653  10.          35.        ]\n",
      " [  1.17372993  10.          35.        ]\n",
      " [  1.17881943  10.          35.        ]\n",
      " [  1.60761094   5.          36.        ]\n",
      " [  1.56589151   6.          36.        ]\n",
      " [  2.19385264   3.          37.        ]\n",
      " [  2.13393636   3.          37.        ]\n",
      " [  1.47770164   7.          36.        ]\n",
      " [  1.96685312   4.          37.        ]\n",
      " [  1.97117208   4.          37.        ]\n",
      " [  1.40839502   8.          36.        ]\n",
      " [  1.82546211   5.          37.        ]\n",
      " [  1.42018619   9.          36.        ]\n",
      " [  2.4382773    3.          38.        ]\n",
      " [  1.86280826   6.0432866   37.47618692]\n",
      " [  1.49493969   9.          37.        ]\n",
      " [  1.51141081   9.          38.        ]\n",
      " [  1.08247014   7.          37.52647893]]\n",
      "[  2.67332096   2.69360897   2.69362749   2.69363199   2.69573102\n",
      "   2.70532638   2.70841138   2.79382585   2.79447762   2.79628699\n",
      "   2.89151789   2.91318564   2.96533115   2.98517556   3.09584258\n",
      "   3.19542019   3.19835425   3.28890316   3.4601353    3.63290864\n",
      "   3.94822245   4.05039558   4.46565444   8.3970085   20.21622241]\n",
      "22.2066099025\n",
      "Program execution time was 0.263951.\n",
      "\n",
      "2.67332095869\n",
      "3755\n",
      "[1.2076510330422581, 9.0, 0.28299999999999997]\n",
      "\n",
      "(1.8159208942700297e+34, [4261361972.8661871, 1680681.4207268909, 0.191, -1.7923489669577419, -131.18344811580647, 504202.59503306734, 0.0, -1176485.4717438237])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import ObjectiveFunctions as of\n",
    "import GnoweeUtilities as util\n",
    "import Gnowee\n",
    "\n",
    "opt_funct=of.MI_Spring_Obj\n",
    "opt_params=of.Get_Params(opt_funct,'Gnowee',dimension=3)\n",
    "\n",
    "S=util.Settings(optimal_fitness=opt_params.o)\n",
    "S.s='nolh-cdr'\n",
    "S.p=25\n",
    "S.a=0.5\n",
    "S.fd=0.2\n",
    "S.fe=0.1\n",
    "S.fl=0.2\n",
    "S.s='lhc'\n",
    "S.sl=40\n",
    "S.sf=10\n",
    "S.em=200000\n",
    "(timeline)=Gnowee.main(opt_funct,opt_params.lb,opt_params.ub,opt_params.vt,S,discreteVals=opt_params.dv)\n",
    "\n",
    "print\n",
    "print timeline[-1].f\n",
    "print timeline[-1].e\n",
    "print timeline[-1].d\n",
    "print\n",
    "print of.MI_Spring_Obj(timeline[-1].d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2171219524948.0283, [-2618.4169953655219, -9.0122019238442483, -0.08299999999999996, -1.7923489669577419, -1.2673181379585099, -5.4842555771532746, -8.8817841970012523e-16, 0.046596346690973567])\n"
     ]
    }
   ],
   "source": [
    "print of.MI_Spring_Obj(np.array([1.2076510330422581, 9.0, 35]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyKriging  \n",
    "from pyKriging.krige import kriging  \n",
    "from pyKriging.samplingplan import samplingplan\n",
    "import numpy as np\n",
    "import ObjectiveFunctions as of\n",
    "import GnoweeUtilities as util\n",
    "\n",
    "opt_funct=of.MI_Spring_Obj\n",
    "opt_params=of.Get_Params(opt_funct,'Gnowee',dimension=6)\n",
    "opt_params.lb.append(0)\n",
    "opt_params.ub.append(41)\n",
    "\n",
    "# The Kriging model starts by defining a sampling plan, we use an optimal Latin Hypercube here\n",
    "sp = samplingplan(2)  \n",
    "X = sp.optimallhc(20)\n",
    "X1=np.array([[  1.22989779,   9.,          35.93307958],\n",
    " [  1.97495591,   4.,          37.        ],\n",
    " [  1.97495612,   4.,          37.        ],\n",
    " [  1.97497135,   4.,          37.        ],\n",
    " [  1.97497227,   4.,          37.        ],\n",
    " [  1.97497557,   4.,          37.        ],\n",
    " [  1.97498173,   4.,          37.        ],\n",
    " [  1.97505063,   4.,          37.        ],\n",
    " [  1.9750696,    4.,          37.        ],\n",
    " [  1.97855739,   4.,          37.        ],\n",
    " [  1.98268578,   4.,          37.        ],\n",
    " [  1.98646116,   4.,          37.        ],\n",
    " [  2.00386279,   4.,          37.        ],\n",
    " [  2.02884805,   4.,          37.        ],\n",
    " [  2.03506503,   4.,          37.        ],\n",
    " [  1.83352703,   5.,          37.        ],\n",
    " [  1.83408116,   5.,          37.        ],\n",
    " [  1.94437431,   5.,          37.        ],\n",
    " [  1.94752622,   5.,          37.        ],\n",
    " [  2.322291,     8.76262526,  39.        ],\n",
    " [  1.22150502,   8.24505967,  39.91483704],\n",
    " [  0.37771301,   5.83021997,  34.79128737],\n",
    " [  0.14741857,   8.75251546,  27.47298103],\n",
    " [  0.11040168,   2.,          27.31492518],\n",
    " [  0.07408576,   5.01380742,  28.08592449]])\n",
    "#print X\n",
    "\n",
    "# Next, we define the problem we would like to solve\n",
    "testfun = pyKriging.testfunctions().branin  \n",
    "y = testfun(X)\n",
    "y1=np.array([  2.67346394e+00,   3.20335003e+00,   3.20335038e+00,   3.20337508e+00,\n",
    "   3.20337657e+00,   3.20338192e+00,   3.20339191e+00,   3.20350367e+00,\n",
    "   3.20353444e+00,   3.20919157e+00,   3.21588776e+00,   3.22201138e+00,\n",
    "   3.25023658e+00,   3.29076230e+00,   3.30084616e+00,   3.46961350e+00,\n",
    "   3.47066208e+00,   3.67937163e+00,   3.68533604e+00,   9.57341875e+00,\n",
    "   8.95562988e+19,   3.92914070e+20,   5.51059403e+20,   6.63909119e+20,\n",
    "   8.02556664e+20])\n",
    "#print y\n",
    "\n",
    "# Now that we have our initial data, we can create an instance of a Kriging model\n",
    "k = kriging(X, y, testfunction=testfun, name='simple')  \n",
    "#k = kriging(X, y) \n",
    "\n",
    "k.train()\n",
    "\n",
    "# Now, five infill points are added. Note that the model is re-trained after each point is added\n",
    "numiter = 0  \n",
    "for i in range(numiter):  \n",
    "    print 'Infill iteration {0} of {1}....'.format(i + 1, numiter)\n",
    "    newpoints = k.infill(1,'ei')\n",
    "    print newpoints\n",
    "    \n",
    "    for point in newpoints:\n",
    "        point[1]=round(point[1])\n",
    "        point[2]=round(point[2])\n",
    "        print len(point),len(opt_params.lb)\n",
    "        point=util.Simple_Bounds(point,opt_params.lb,opt_params.ub)\n",
    "        print point\n",
    "        print \"Before: \",k.predict(point), opt_funct(point)[0]\n",
    "        k.addPoint(point, opt_funct(point)[0])\n",
    "        print \"After: \",k.predict(point), opt_funct(point)[0]\n",
    "        \n",
    "    newpoints = k.infill(1,'error')\n",
    "    print newpoints\n",
    "    \n",
    "    for point in newpoints:\n",
    "        point[1]=round(point[1])\n",
    "        point[2]=round(point[2])\n",
    "        point=util.Simple_Bounds(point,opt_params.lb,opt_params.ub)\n",
    "        print point\n",
    "        print \"Before: \",k.predict(point), opt_funct(point)[0]\n",
    "        k.addPoint(point, opt_funct(point)[0])\n",
    "        print \"After: \",k.predict(point), opt_funct(point)[0]\n",
    "    k.train()\n",
    "\n",
    "# And plot the results\n",
    "k.plot()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.475  0.025]\n",
      " [ 0.425  0.425]\n",
      " [ 0.625  0.925]\n",
      " [ 0.025  0.825]\n",
      " [ 0.725  0.075]\n",
      " [ 0.375  0.775]\n",
      " [ 0.225  0.975]\n",
      " [ 0.975  0.875]\n",
      " [ 0.875  0.575]\n",
      " [ 0.775  0.725]\n",
      " [ 0.125  0.175]\n",
      " [ 0.575  0.225]\n",
      " [ 0.675  0.475]\n",
      " [ 0.275  0.625]\n",
      " [ 0.525  0.675]\n",
      " [ 0.825  0.325]\n",
      " [ 0.075  0.525]\n",
      " [ 0.925  0.125]\n",
      " [ 0.325  0.275]\n",
      " [ 0.175  0.375]]\n",
      "[  15.30973844   19.37148401  162.8485081    23.34385067   22.43849989\n",
      "   62.81707961   43.06748015  115.20981522   61.19918607  117.96512116\n",
      "   93.37937367    6.46636718   51.90083418   21.07744866   61.62346487\n",
      "   31.41157515   42.07993633    6.4685785    25.46181277   27.80846402]\n",
      "[ 0.575  0.225] 6.46636718467\n"
     ]
    }
   ],
   "source": [
    "print X\n",
    "print y\n",
    "print X[11], y[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   status: 0\n",
      "  success: True\n",
      "     njev: 24\n",
      "     nfev: 96\n",
      " hess_inv: array([[  3.60034190e-04,   2.70197575e-05],\n",
      "       [  2.70197575e-05,   5.77275020e-05]])\n",
      "      fun: 1.8079750033500854\n",
      "        x: array([ 0.52647078,  0.179784  ])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "      jac: array([ 0.,  0.])\n",
      "      nit: 12\n",
      "[ 0.52647078  0.179784  ]\n",
      "1.80797500335 1.80797500335\n",
      "   status: 0\n",
      "  success: True\n",
      "     njev: 1\n",
      "     nfev: 4\n",
      " hess_inv: array([[1, 0],\n",
      "       [0, 1]])\n",
      "      fun: 1.8079750033500854\n",
      "        x: array([ 0.52647078,  0.179784  ])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "      jac: array([ 0.,  0.])\n",
      "      nit: 0\n",
      "[ 0.52647078  0.179784  ]\n",
      "1.80797500335\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def funct(x):\n",
    "    v=k.predict(x)\n",
    "    return v\n",
    "\n",
    "minRes=minimize(funct,X[11])\n",
    "print minRes\n",
    "print minRes.x\n",
    "print k.predict(minRes.x),funct(minRes.x)\n",
    "\n",
    "minRes=minimize(funct,minRes.x)\n",
    "print minRes\n",
    "print minRes.x\n",
    "print k.predict(minRes.x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   status: 0\n",
      "  success: True\n",
      "     nfev: 6\n",
      " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
      "      fun: 0.93507887668493772\n",
      "        x: array([ 1.,  0.])\n",
      "  message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "      jac: array([-0.88649384,  0.08833808])\n",
      "      nit: 1\n",
      "[ 1.  0.]\n",
      "0.935078876685 0.935078876685\n",
      "0.91408479876\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def efunct(x):\n",
    "    v=1-k.predict_var(x)\n",
    "    return v\n",
    "\n",
    "minRes=minimize(efunct,X[11],bounds=((0,1),(0,1)))\n",
    "print minRes\n",
    "print minRes.x\n",
    "print 1-k.predict_var(minRes.x), efunct(minRes.x)\n",
    "\n",
    "print efunct(np.array([0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.22989779   9.          35.93307958]\n",
      " [  1.97495591   4.          37.        ]\n",
      " [  1.97495612   4.          37.        ]\n",
      " [  1.97497135   4.          37.        ]\n",
      " [  1.97497227   4.          37.        ]\n",
      " [  1.97497557   4.          37.        ]\n",
      " [  1.97498173   4.          37.        ]\n",
      " [  1.97505063   4.          37.        ]\n",
      " [  1.9750696    4.          37.        ]\n",
      " [  1.97855739   4.          37.        ]\n",
      " [  1.98268578   4.          37.        ]\n",
      " [  1.98646116   4.          37.        ]\n",
      " [  2.00386279   4.          37.        ]\n",
      " [  2.02884805   4.          37.        ]\n",
      " [  2.03506503   4.          37.        ]\n",
      " [  1.83352703   5.          37.        ]\n",
      " [  1.83408116   5.          37.        ]\n",
      " [  1.94437431   5.          37.        ]\n",
      " [  1.94752622   5.          37.        ]\n",
      " [  2.322291     8.76262526  39.        ]\n",
      " [  1.22150502   8.24505967  39.91483704]\n",
      " [  0.37771301   5.83021997  34.79128737]\n",
      " [  0.14741857   8.75251546  27.47298103]\n",
      " [  0.11040168   2.          27.31492518]\n",
      " [  0.07408576   5.01380742  28.08592449]\n",
      " [  2.8206       3.           6.        ]\n",
      " [  0.4286       1.          35.        ]\n",
      " [  0.7874       9.          30.        ]\n",
      " [  2.701        4.          25.        ]\n",
      " [  2.4618       6.          32.        ]\n",
      " [  1.2658       3.          39.        ]\n",
      " [  2.103        2.          27.        ]\n",
      " [  1.9834       4.          37.        ]\n",
      " [  0.1894       8.          11.        ]\n",
      " [  1.8638       9.           9.        ]\n",
      " [  0.907        7.          20.        ]\n",
      " [  1.0266       8.          29.        ]\n",
      " [  2.3422       5.           1.        ]\n",
      " [  0.6678      10.           7.        ]\n",
      " [  0.0698       5.          19.        ]\n",
      " [  2.9402       2.          17.        ]\n",
      " [  1.7442       2.           2.        ]\n",
      " [  1.6246       6.          40.        ]\n",
      " [  1.3854       7.          34.        ]\n",
      " [  0.5482       6.          12.        ]\n",
      " [  2.2226       4.          16.        ]\n",
      " [  1.1462       8.          22.        ]\n",
      " [  1.505        3.           4.        ]\n",
      " [  2.5814       9.          14.        ]\n",
      " [  0.309        7.          24.        ]]\n",
      "[  2.67346394e+00   3.20335003e+00   3.20335038e+00   3.20337508e+00\n",
      "   3.20337657e+00   3.20338192e+00   3.20339191e+00   3.20350367e+00\n",
      "   3.20353444e+00   3.20919157e+00   3.21588776e+00   3.22201138e+00\n",
      "   3.25023658e+00   3.29076230e+00   3.30084616e+00   3.46961350e+00\n",
      "   3.47066208e+00   3.67937163e+00   3.68533604e+00   9.57341875e+00\n",
      "   8.95562988e+19   3.92914070e+20   5.51059403e+20   6.63909119e+20\n",
      "   8.02556664e+20   6.94406573e+38   3.75433961e+20   4.21432150e+30\n",
      "   1.63127023e+33   1.88194154e+31   1.27024598e+20   2.65113474e+32\n",
      "   3.21704622e+00   4.80976443e+35   8.61424821e+37   9.91932607e+33\n",
      "   1.64904822e+31   4.89293809e+39   2.69691199e+37   1.90993796e+33\n",
      "   1.22166074e+36   1.67453257e+33   8.24546300e+19   3.80123867e+29\n",
      "   1.47075805e+36   1.81388509e+36   3.69328257e+33   3.41725374e+38\n",
      "   9.22454178e+36   8.01314667e+31]\n"
     ]
    }
   ],
   "source": [
    "import pyKriging  \n",
    "from pyKriging.krige import kriging  \n",
    "from pyKriging.samplingplan import samplingplan\n",
    "import numpy as np\n",
    "import ObjectiveFunctions as of\n",
    "import GnoweeUtilities as util\n",
    "from scipy.optimize import minimize\n",
    "import SamplingMethods as sm\n",
    "\n",
    "opt_funct=of.MI_Spring_Obj\n",
    "opt_params=of.Get_Params(opt_funct,'Gnowee',dimension=6)\n",
    "opt_params.lb.append(0)\n",
    "opt_params.ub.append(41)\n",
    "\n",
    "# The Kriging model starts by defining a sampling plan, we use an optimal Latin Hypercube here \n",
    "X=np.array([[  1.22989779,   9.,          35.93307958],\n",
    " [  1.97495591,   4.,          37.        ],\n",
    " [  1.97495612,   4.,          37.        ],\n",
    " [  1.97497135,   4.,          37.        ],\n",
    " [  1.97497227,   4.,          37.        ],\n",
    " [  1.97497557,   4.,          37.        ],\n",
    " [  1.97498173,   4.,          37.        ],\n",
    " [  1.97505063,   4.,          37.        ],\n",
    " [  1.9750696,    4.,          37.        ],\n",
    " [  1.97855739,   4.,          37.        ],\n",
    " [  1.98268578,   4.,          37.        ],\n",
    " [  1.98646116,   4.,          37.        ],\n",
    " [  2.00386279,   4.,          37.        ],\n",
    " [  2.02884805,   4.,          37.        ],\n",
    " [  2.03506503,   4.,          37.        ],\n",
    " [  1.83352703,   5.,          37.        ],\n",
    " [  1.83408116,   5.,          37.        ],\n",
    " [  1.94437431,   5.,          37.        ],\n",
    " [  1.94752622,   5.,          37.        ],\n",
    " [  2.322291,     8.76262526,  39.        ],\n",
    " [  1.22150502,   8.24505967,  39.91483704],\n",
    " [  0.37771301,   5.83021997,  34.79128737],\n",
    " [  0.14741857,   8.75251546,  27.47298103],\n",
    " [  0.11040168,   2.,          27.31492518],\n",
    " [  0.07408576,   5.01380742,  28.08592449]])\n",
    "#print X\n",
    "\n",
    "# Next, we define the problem we would like to solve\n",
    "Y=np.array([  2.67346394e+00,   3.20335003e+00,   3.20335038e+00,   3.20337508e+00,\n",
    "   3.20337657e+00,   3.20338192e+00,   3.20339191e+00,   3.20350367e+00,\n",
    "   3.20353444e+00,   3.20919157e+00,   3.21588776e+00,   3.22201138e+00,\n",
    "   3.25023658e+00,   3.29076230e+00,   3.30084616e+00,   3.46961350e+00,\n",
    "   3.47066208e+00,   3.67937163e+00,   3.68533604e+00,   9.57341875e+00,\n",
    "   8.95562988e+19,   3.92914070e+20,   5.51059403e+20,   6.63909119e+20,\n",
    "   8.02556664e+20])\n",
    "#print y\n",
    "\n",
    "init=sm.Initial_Samples(np.array(opt_params.lb),np.array(opt_params.ub),'lhc',25)\n",
    "init[:,1:]=np.rint(init[:,1:])\n",
    "initY=[]\n",
    "for i in init:\n",
    "    initY.append(opt_funct(i)[0])\n",
    "X=np.concatenate((X,init),axis=0)\n",
    "Y=np.concatenate((Y,initY),axis=0)\n",
    "print X\n",
    "print Y\n",
    "\n",
    "# Now that we have our initial data, we can create an instance of a Kriging model\n",
    "k = kriging(X, Y) \n",
    "\n",
    "k.train()\n",
    "\n",
    "n=0\n",
    "for i in range(n):\n",
    "    # Choose point based on current best location\n",
    "    def funct(x):\n",
    "        x[1]=round(x[1])\n",
    "        x[2]=round(x[2])\n",
    "        v=k.predict(x)\n",
    "        return v\n",
    "\n",
    "    print \"Iter #{}, best point method:\".format(n)\n",
    "    print X[1]\n",
    "    print opt_funct(X[1])[0]\n",
    "\n",
    "    minVal=minimize(funct,X[1],bounds=((0,3),(1,10),(0,41)))\n",
    "    k.addPoint(minVal.x,opt_funct(minVal.x)[0])\n",
    "    print minVal\n",
    "    print minVal.x\n",
    "    print k.predict(minVal.x),opt_funct(minVal.x)[0]\n",
    "    print\n",
    "    \n",
    "    # Choose point based on variance of model\n",
    "    print \"Iter #{}, variance reduction method:\".format(n)\n",
    "    x_var=k.infill(1,'error')[0]\n",
    "    print x_var\n",
    "\n",
    "    def efunct(x):\n",
    "        x[1]=round(x[1])\n",
    "        x[2]=round(x[2])\n",
    "        v=1-k.predict_var(x)\n",
    "        return v\n",
    "\n",
    "    minErr=minimize(efunct,x_var,bounds=((0.01,3),(1,10),(0,41)))\n",
    "    k.addPoint(minErr.x,opt_funct(minErr.x)[0])\n",
    "    print minErr\n",
    "    print minErr.x\n",
    "    print 1-k.predict_var(minErr.x)\n",
    "    print \n",
    "    \n",
    "    k.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter #0, best point method:\n",
      "[  1.97495591   4.          37.        ]\n",
      "-1.69436709363e+29 3.20335003025\n",
      "   status: 2\n",
      "  success: False\n",
      "     nfev: 84\n",
      " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
      "      fun: -1.6943670936284649e+29\n",
      "        x: array([  1.97495591,   4.        ,  37.        ])\n",
      "  message: 'ABNORMAL_TERMINATION_IN_LNSRCH'\n",
      "      jac: array([  8.90020253e+35,   0.00000000e+00,   0.00000000e+00])\n",
      "      nit: 0\n",
      "[  1.97495591   4.          37.        ]\n",
      "2.05058705272e+28 3.20335003025\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Choose point based on current best location\n",
    "def funct(x):\n",
    "    x[1]=round(x[1])\n",
    "    x[2]=round(x[2])\n",
    "    v=k.predict(x)\n",
    "    return v\n",
    "\n",
    "print \"Iter #{}, best point method:\".format(n)\n",
    "print X[1]\n",
    "print k.predict(X[1]),opt_funct(X[1])[0]\n",
    "\n",
    "minVal=minimize(funct,X[1],bounds=((0.01,3),(1,10),(0,41)))\n",
    "k.addPoint(minVal.x,opt_funct(minVal.x)[0])\n",
    "print minVal\n",
    "print minVal.x\n",
    "print k.predict(minVal.x),opt_funct(minVal.x)[0]\n",
    "print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.0501909    0.32123686  13.80346665]\n",
      " [  0.05193759   0.35987732  11.21194855]\n",
      " [  0.05047078   0.32618961  13.52238681]\n",
      " [  0.05155328   0.35143536  11.83943881]\n",
      " [  0.05         0.31378522  14.56518177]\n",
      " [  0.05002886   0.31364893  14.58370358]\n",
      " [  0.0547937    0.43460327   8.00007585]\n",
      " [  0.05032471   0.3207653   14.18483223]\n",
      " [  0.05011247   0.31789771  14.50714541]\n",
      " [  0.05458181   0.42738777   8.49534384]\n",
      " [  0.05570803   0.45234829   7.59743872]\n",
      " [  0.05570803   0.45234829   7.59743872]\n",
      " [  0.0572067    0.50042069   6.29375968]\n",
      " [  0.05108934   0.32846657  13.99241058]\n",
      " [  0.05278429   0.37744258  11.12826427]\n",
      " [  0.05104608   0.33788833  13.71959408]\n",
      " [  0.05385014   0.38688463  10.43134295]\n",
      " [  0.05152156   0.33619841  13.71061663]\n",
      " [  0.05192719   0.33867099  13.48449431]\n",
      " [  0.05999931   0.57635593   4.90038847]\n",
      " [  0.06015361   0.58058734   4.89100305]\n",
      " [  0.05662418   0.45075934   8.11667537]\n",
      " [  0.0637329    0.69904064   3.47029334]]\n",
      "[ 0.01278874  0.01282581  0.01289759  0.01292637  0.01299477  0.01301867\n",
      "  0.01304841  0.01314795  0.01317805  0.01336333  0.01347299  0.01347299\n",
      "  0.01358252  0.01371089  0.01380599  0.0138401   0.01394676  0.01402061\n",
      "  0.0141405   0.01431716  0.01447683  0.01462132  0.01553246]\n"
     ]
    }
   ],
   "source": [
    "import pyKriging  \n",
    "from pyKriging.krige import kriging  \n",
    "from pyKriging.samplingplan import samplingplan\n",
    "import numpy as np\n",
    "import ObjectiveFunctions as of\n",
    "import GnoweeUtilities as util\n",
    "from scipy.optimize import minimize\n",
    "import SamplingMethods as sm\n",
    "\n",
    "opt_funct=of.Spring_Obj\n",
    "opt_params=of.Get_Params(opt_funct,'Gnowee',dimension=3)\n",
    "\n",
    "# The Kriging model starts by defining a sampling plan, we use an optimal Latin Hypercube here \n",
    "xOut=np.array([[  0.0501909,    0.32123686,  13.80346665],\n",
    " [  0.05193759,   0.35987732,  11.21194855],\n",
    " [  0.05047078,   0.32618961,  13.52238681],\n",
    " [  0.05155328,   0.35143536,  11.83943881],\n",
    " [  0.05,         0.31378522,  14.56518177],\n",
    " [  0.05002886,   0.31364893,  14.58370358],\n",
    " [  0.0547937,    0.43460327,   8.00007585],\n",
    " [  0.05032471,   0.3207653 ,  14.18483223],\n",
    " [  0.05011247,   0.31789771,  14.50714541],\n",
    " [  0.05458181,   0.42738777,   8.49534384],\n",
    " [  0.05570803,   0.45234829,   7.59743872],\n",
    " [  0.05570803,   0.45234829,   7.59743872],\n",
    " [  0.0572067 ,   0.50042069,   6.29375968],\n",
    " [  0.05108934,   0.32846657,  13.99241058],\n",
    " [  0.05278429,   0.37744258,  11.12826427],\n",
    " [  0.05104608,   0.33788833,  13.71959408],\n",
    " [  0.05385014,   0.38688463,  10.43134295],\n",
    " [  0.05152156,   0.33619841,  13.71061663],\n",
    " [  0.05192719,   0.33867099,  13.48449431],\n",
    " [  0.05999931,   0.57635593,   4.90038847],\n",
    " [  0.06015361,   0.58058734,   4.89100305],\n",
    " [  0.05662418,   0.45075934,   8.11667537],\n",
    " [  0.0637329 ,   0.69904064,   3.47029334],])\n",
    "yOut=np.array([  1.27887395e-02,   1.28258137e-02,   1.28975945e-02,   1.29263701e-02,\n",
    "   1.29947729e-02,   1.30186680e-02,   1.30484065e-02,   1.31479523e-02,\n",
    "   1.31780457e-02,   1.33633270e-02,   1.34729879e-02,   1.34729879e-02,\n",
    "   1.35825235e-02,   1.37108913e-02,   1.38059894e-02,   1.38401047e-02,\n",
    "   1.39467568e-02,   1.40206102e-02,   1.41404954e-02,   1.43171577e-02,\n",
    "   1.44768264e-02,   1.46213161e-02,   1.55324642e-02])\n",
    "X=sm.Initial_Samples(np.array(opt_params.lb),np.array(opt_params.ub),'lhc',125)\n",
    "Y=[]\n",
    "#for i in X:\n",
    "#    Y.append(opt_funct(i,1)[0])\n",
    "#X=np.concatenate((X,xOut),axis=0)\n",
    "#Y=np.concatenate((Y,yOut),axis=0)\n",
    "X=xOut\n",
    "Y=yOut\n",
    "print X\n",
    "print Y\n",
    "\n",
    "# Now that we have our initial data, we can create an instance of a Kriging model\n",
    "k = kriging(X, Y) \n",
    "\n",
    "k.train()\n",
    "\n",
    "# Choose point based on current best location\n",
    "def funct(x):\n",
    "    v=k.predict(x)\n",
    "    return v\n",
    "def efunct(x):\n",
    "    v=1-k.predict_var(x)\n",
    "    return v\n",
    "\n",
    "n=0\n",
    "for i in range(n):\n",
    "\n",
    "    print \"Iter #{}, best point method:\".format(n)\n",
    "    print X[1]\n",
    "    print opt_funct(X[1])[0]\n",
    "\n",
    "    minVal=minimize(funct,X[1],bounds=((0,3),(1,10),(0,41)))\n",
    "    k.addPoint(minVal.x,opt_funct(minVal.x)[0])\n",
    "    print minVal\n",
    "    print minVal.x\n",
    "    print k.predict(minVal.x),opt_funct(minVal.x)[0]\n",
    "    print\n",
    "    \n",
    "    # Choose point based on variance of model\n",
    "    print \"Iter #{}, variance reduction method:\".format(n)\n",
    "    x_var=k.infill(1,'error')[0]\n",
    "    print x_var\n",
    "\n",
    "\n",
    "    minErr=minimize(efunct,x_var,bounds=((0.01,3),(1,10),(0,41)))\n",
    "    k.addPoint(minErr.x,opt_funct(minErr.x)[0])\n",
    "    print minErr\n",
    "    print minErr.x\n",
    "    print 1-k.predict_var(minErr.x)\n",
    "    print \n",
    "    \n",
    "    k.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter #0, best point method:\n",
      "[  0.0501909    0.32123686  13.80346665]\n",
      "0.0127887394869 0.0127887383801\n",
      "   status: 0\n",
      "  success: True\n",
      "     nfev: 84\n",
      " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
      "      fun: 0.0098481711154389858\n",
      "        x: array([  0.05      ,   0.25      ,  13.78919375])\n",
      "  message: 'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "      jac: array([ 0.38219344,  0.04463178, -0.00604936])\n",
      "      nit: 4\n",
      "[  0.05         0.25        13.78919375]\n",
      "1.00986691394 1.00986824609\n",
      "\n",
      "[[ 1.00867455  1.02638265  5.13798718]]\n",
      "0.0021429123955 9.45396230822\n",
      "\n",
      "0.0117467913971 0.0126653101469\n"
     ]
    }
   ],
   "source": [
    "# Choose point based on current best location\n",
    "def funct(x):\n",
    "    v=k.predict(x)\n",
    "    return v\n",
    "\n",
    "print \"Iter #{}, best point method:\".format(n)\n",
    "print X[0]\n",
    "print k.predict(X[0]),opt_funct(X[0],1)[0]\n",
    "\n",
    "minVal=minimize(funct,X[0],bounds=((0.05,2.0),(0.25,1.3),(2.0,15.0)))\n",
    "k.addPoint(minVal.x,opt_funct(minVal.x,1)[0])\n",
    "print minVal\n",
    "print minVal.x\n",
    "print k.predict(minVal.x),opt_funct(minVal.x,1)[0]\n",
    "print\n",
    "\n",
    "test=sm.Initial_Samples(np.array(opt_params.lb),np.array(opt_params.ub),'random',1)\n",
    "print test\n",
    "print k.predict(test[0]),opt_funct(test[0],1)[0]\n",
    "print\n",
    "\n",
    "optim=np.array([0.05169046,0.356750, 11.287126]) \n",
    "print k.predict(optim),opt_funct(optim,1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
