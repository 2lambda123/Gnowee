{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Gnowee\n",
    "\n",
    "This scipt is the bare minimum needed to run Gnowee.  \n",
    "\n",
    "Different objective functions can be added to the ObjectiveFunctions module by following the examples shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitness Convergence\n",
      "Program execution time was 0.377717971802.\n",
      "\n",
      "The result:\n",
      "Event:\n",
      "Generation # = 106\n",
      "Evaluation # = 3129\n",
      "Fitness = 2.6691430509\n",
      "Design = [1.2279100102390799, 9.0, 0.28299999999999997]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gnowee Modules\n",
    "import Gnowee\n",
    "import ObjectiveFunctions as of\n",
    "from GnoweeHeuristics import GnoweeHeuristics\n",
    "\n",
    "# Select optimization problem type and associated parameters\n",
    "optFunc = of.MI_Spring_Obj\n",
    "\n",
    "# Run optimization\n",
    "optParams = of.Get_Params(optFunc, 'Gnowee')\n",
    "gh = GnoweeHeuristics(optimalFitness=optParams.o)\n",
    "(timeline) = Gnowee.main(optFunc, optParams.lb, optParams.ub, optParams.vt, gh, \n",
    "                             discreteVals=optParams.dv)\n",
    "print '\\nThe result:\\n', timeline[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Gnowee\n",
    "\n",
    "This scipt runs multipe instances of Gnowee against an optimization prolem.  It is useful for benchmarking and understanding the distribution of solutions obtained by Gnowee for a particular problem.  Statistics and plots are obtained and shown following the optimization process.  \n",
    "\n",
    "Different objective functions can be added to the ObjectiveFunctions module by following the examples shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run #0\n",
      "Fitness Convergence\n",
      "Program execution time was 0.237861871719.\n",
      "Run #1\n",
      "Fitness Convergence\n",
      "Program execution time was 0.392526865005.\n",
      "Run #2\n",
      "Fitness Convergence\n",
      "Program execution time was 1.14041996002.\n",
      "Run #3\n",
      "Fitness Convergence\n",
      "Program execution time was 0.600648164749.\n",
      "Run #4\n",
      "Generational Stall at generation #382\n",
      "Program execution time was 1.48218607903.\n",
      "Run #5\n",
      "Fitness Convergence\n",
      "Program execution time was 0.117486000061.\n",
      "Run #6\n",
      "Fitness Convergence\n",
      "Program execution time was 0.0941488742828.\n",
      "Run #7\n",
      "Generational Stall at generation #479\n",
      "Program execution time was 1.8167078495.\n",
      "Run #8\n",
      "Fitness Convergence\n",
      "Program execution time was 0.536452054977.\n",
      "Run #9\n",
      "Generational Stall at generation #429\n",
      "Program execution time was 1.70115804672.\n",
      "Run #10\n",
      "Fitness Convergence\n",
      "Program execution time was 0.331743001938.\n",
      "Run #11\n",
      "Generational Stall at generation #420\n",
      "Program execution time was 1.58184695244.\n",
      "Run #12\n",
      "Fitness Convergence\n",
      "Program execution time was 0.382843971252.\n",
      "Run #13\n",
      "Generational Stall at generation #419\n",
      "Program execution time was 1.55519294739.\n",
      "Run #14\n",
      "Fitness Convergence\n",
      "Program execution time was 0.523741006851.\n",
      "Run #15\n",
      "Fitness Convergence\n",
      "Program execution time was 0.296747922897.\n",
      "Run #16\n",
      "Generational Stall at generation #401\n",
      "Program execution time was 1.50180315971.\n",
      "Run #17\n",
      "Fitness Convergence\n",
      "Program execution time was 0.23860001564.\n",
      "Run #18\n",
      "Generational Stall at generation #404\n",
      "Program execution time was 1.50060915947.\n",
      "Run #19\n",
      "Generational Stall at generation #423\n",
      "Program execution time was 1.5585038662.\n",
      "Run #20\n",
      "Fitness Convergence\n",
      "Program execution time was 0.454424142838.\n",
      "Run #21\n",
      "Fitness Convergence\n",
      "Program execution time was 0.445336103439.\n",
      "Run #22\n",
      "Generational Stall at generation #476\n",
      "Program execution time was 1.73194503784.\n",
      "Run #23\n",
      "Generational Stall at generation #354\n",
      "Program execution time was 1.34097003937.\n",
      "Run #24\n",
      "Generational Stall at generation #396\n",
      "Program execution time was 1.46897292137.\n",
      "Run #25\n",
      "Generational Stall at generation #735\n",
      "Program execution time was 2.84676098824.\n",
      "Run #26\n",
      "Generational Stall at generation #361\n",
      "Program execution time was 1.35034394264.\n",
      "Run #27\n",
      "Fitness Convergence\n",
      "Program execution time was 0.0756158828735.\n",
      "Run #28\n",
      "Generational Stall at generation #404\n",
      "Program execution time was 1.5142159462.\n",
      "Run #29\n",
      "Generational Stall at generation #395\n",
      "Program execution time was 1.49005818367.\n",
      "Run #30\n",
      "Fitness Convergence\n",
      "Program execution time was 1.22574305534.\n",
      "Run #31\n",
      "Fitness Convergence\n",
      "Program execution time was 0.161381959915.\n",
      "Run #32\n",
      "Generational Stall at generation #419\n",
      "Program execution time was 1.71897888184.\n",
      "Run #33\n",
      "Fitness Convergence\n",
      "Program execution time was 0.403546094894.\n",
      "Run #34\n",
      "Fitness Convergence\n",
      "Program execution time was 0.491532087326.\n",
      "Run #35\n",
      "Generational Stall at generation #434\n",
      "Program execution time was 1.71031093597.\n",
      "Run #36\n",
      "Fitness Convergence\n",
      "Program execution time was 0.259572029114.\n",
      "Run #37\n",
      "Generational Stall at generation #485\n",
      "Program execution time was 1.92865896225.\n",
      "Run #38\n",
      "Generational Stall at generation #430\n",
      "Program execution time was 1.66394710541.\n",
      "Run #39\n",
      "Fitness Convergence\n",
      "Program execution time was 1.52907419205.\n",
      "Run #40\n",
      "Generational Stall at generation #427\n",
      "Program execution time was 1.53929209709.\n",
      "Run #41\n",
      "Generational Stall at generation #401\n",
      "Program execution time was 1.50750613213.\n",
      "Run #42\n",
      "Generational Stall at generation #430\n",
      "Program execution time was 1.57937598228.\n",
      "Run #43\n",
      "Generational Stall at generation #391\n",
      "Program execution time was 1.48966407776.\n",
      "Run #44\n",
      "Fitness Convergence\n",
      "Program execution time was 0.402659893036.\n",
      "Run #45\n",
      "Fitness Convergence\n",
      "Program execution time was 0.440006971359.\n",
      "Run #46\n",
      "Fitness Convergence\n",
      "Program execution time was 0.173800945282.\n",
      "Run #47\n",
      "Fitness Convergence\n",
      "Program execution time was 0.394157886505.\n",
      "Run #48\n",
      "Fitness Convergence\n",
      "Program execution time was 0.13053393364.\n",
      "Run #49\n",
      "Fitness Convergence\n",
      "Program execution time was 0.924900054932.\n",
      "Run #50\n",
      "Generational Stall at generation #418\n",
      "Program execution time was 1.56601214409.\n",
      "Run #51\n",
      "Generational Stall at generation #390\n",
      "Program execution time was 1.44533514977.\n",
      "Run #52\n",
      "Fitness Convergence\n",
      "Program execution time was 0.463936090469.\n",
      "Run #53\n",
      "Fitness Convergence\n",
      "Program execution time was 1.13152503967.\n",
      "Run #54\n",
      "Fitness Convergence\n",
      "Program execution time was 0.0760109424591.\n",
      "Run #55\n",
      "Generational Stall at generation #375\n",
      "Program execution time was 1.40873789787.\n",
      "Run #56\n",
      "Generational Stall at generation #434\n",
      "Program execution time was 1.6208729744.\n",
      "Run #57\n",
      "Fitness Convergence\n",
      "Program execution time was 0.0938060283661.\n",
      "Run #58\n",
      "Generational Stall at generation #477\n",
      "Program execution time was 1.78094792366.\n",
      "Run #59\n",
      "Fitness Convergence\n",
      "Program execution time was 0.673926830292.\n",
      "Run #60\n",
      "Fitness Convergence\n",
      "Program execution time was 0.413391113281.\n",
      "Run #61\n",
      "Generational Stall at generation #552\n",
      "Program execution time was 2.09443807602.\n",
      "Run #62\n",
      "Fitness Convergence\n",
      "Program execution time was 0.584090948105.\n",
      "Run #63\n",
      "Generational Stall at generation #465\n",
      "Program execution time was 2.10173797607.\n",
      "Run #64\n",
      "Generational Stall at generation #403\n",
      "Program execution time was 1.4445130825.\n",
      "Run #65\n",
      "Fitness Convergence\n",
      "Program execution time was 0.519826173782.\n",
      "Run #66\n",
      "Fitness Convergence\n",
      "Program execution time was 0.899036884308.\n",
      "Run #67\n",
      "Generational Stall at generation #404\n",
      "Program execution time was 1.53302812576.\n",
      "Run #68\n",
      "Generational Stall at generation #449\n",
      "Program execution time was 1.76314616203.\n",
      "Run #69\n",
      "Generational Stall at generation #446\n",
      "Program execution time was 2.0277299881.\n",
      "Run #70\n",
      "Fitness Convergence\n",
      "Program execution time was 1.19488191605.\n",
      "Run #71\n",
      "Fitness Convergence\n",
      "Program execution time was 0.295569896698.\n",
      "Run #72\n",
      "Generational Stall at generation #386\n",
      "Program execution time was 1.66182303429.\n",
      "Run #73\n",
      "Generational Stall at generation #487\n",
      "Program execution time was 2.2391910553.\n",
      "Run #74\n",
      "Generational Stall at generation #438\n",
      "Program execution time was 1.73726010323.\n",
      "Run #75\n",
      "Fitness Convergence\n",
      "Program execution time was 0.530163049698.\n",
      "Run #76\n",
      "Fitness Convergence\n",
      "Program execution time was 0.341694116592.\n",
      "Run #77\n",
      "Generational Stall at generation #377\n",
      "Program execution time was 1.45539689064.\n",
      "Run #78\n",
      "Fitness Convergence\n",
      "Program execution time was 0.394001960754.\n",
      "Run #79\n",
      "Fitness Convergence\n",
      "Program execution time was 0.976335048676.\n",
      "Run #80\n",
      "Generational Stall at generation #558\n",
      "Program execution time was 2.15355205536.\n",
      "Run #81\n",
      "Generational Stall at generation #476\n",
      "Program execution time was 1.83806204796.\n",
      "Run #82\n",
      "Generational Stall at generation #386\n",
      "Program execution time was 1.46837592125.\n",
      "Run #83\n",
      "Generational Stall at generation #386\n",
      "Program execution time was 1.4264998436.\n",
      "Run #84\n",
      "Fitness Convergence\n",
      "Program execution time was 0.297300100327.\n",
      "Run #85\n",
      "Fitness Convergence\n",
      "Program execution time was 1.34000682831.\n",
      "Run #86\n",
      "Generational Stall at generation #402\n",
      "Program execution time was 1.49892687798.\n",
      "Run #87\n",
      "Fitness Convergence\n",
      "Program execution time was 0.0756461620331.\n",
      "Run #88\n",
      "Generational Stall at generation #453\n",
      "Program execution time was 1.79217195511.\n",
      "Run #89\n",
      "Fitness Convergence\n",
      "Program execution time was 0.464861869812.\n",
      "Run #90\n",
      "Generational Stall at generation #391\n",
      "Program execution time was 1.52724289894.\n",
      "Run #91\n",
      "Fitness Convergence\n",
      "Program execution time was 1.39553999901.\n",
      "Run #92\n",
      "Generational Stall at generation #363\n",
      "Program execution time was 1.39047598839.\n",
      "Run #93\n",
      "Generational Stall at generation #515\n",
      "Program execution time was 1.93105196953.\n",
      "Run #94\n",
      "Generational Stall at generation #453\n",
      "Program execution time was 1.68466997147.\n",
      "Run #95\n",
      "Generational Stall at generation #450\n",
      "Program execution time was 1.80573296547.\n",
      "Run #96\n",
      "Generational Stall at generation #372\n",
      "Program execution time was 1.41635918617.\n",
      "Run #97\n",
      "Fitness Convergence\n",
      "Program execution time was 0.266535997391.\n",
      "Run #98\n",
      "Fitness Convergence\n",
      "Program execution time was 0.169724941254.\n",
      "Run #99\n",
      "Fitness Convergence\n",
      "Program execution time was 0.605605840683.\n",
      "\n",
      "The Average Optimized Solution for MI_Spring_Obj:\n",
      "================================\n",
      "Design:\n",
      "   var 1: 1.442876 $\\mypm$ 0.21653 \n",
      "   var 2: 7.000000 $\\mypm$ 2.01008 \n",
      "   var 3: 0.295000 $\\mypm$ 0.01206 \n",
      "Fitness: 2.683802 $\\mypm$ 0.01623 \n",
      "Funct Evals: 9435 $\\mypm$ 5833 \n",
      "Generations: 283.8 $\\mypm$ 169.5 \n",
      "The performance metric is 255.7\n",
      "\n",
      "The Best Optimized Solution for MI_Spring_Obj:\n",
      "================================\n",
      "Design:\n",
      "   var 1: 1.223408 \n",
      "   var 2: 9.000000 \n",
      "   var 3: 0.283000 \n",
      "Fitness: 2.659358 \n",
      "Funct Evals: 4012 \n",
      "Generations: 120 \n",
      "The performance metric is  1.2\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Event' object has no attribute 'd'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-7166d593748d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;32mif\u001b[0m  \u001b[0moptFunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"TSP_Obj\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     op.Plot_Vars(timeline, low_bounds=optParams.lb, up_bounds=optParams.ub, title=optParams.pt,\n\u001b[1;32m--> 179\u001b[1;33m                  label=optParams.l)\n\u001b[0m\u001b[0;32m    180\u001b[0m \u001b[0mfevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluations\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtmp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmaxIter\u001b[0m \u001b[1;33m>\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/pyne-user/Dropbox/UCB/Research/ETAs/Design/Gnowee/src/OptiPlot.pyc\u001b[0m in \u001b[0;36mPlot_Vars\u001b[1;34m(data, low_bounds, up_bounds, title, label, debug)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;31m# Build 1st Subplot - Fitness plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[0mfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m     \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.08\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtmp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Event' object has no attribute 'd'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math as m\n",
    "\n",
    "from operator import attrgetter\n",
    "\n",
    "# Gnowee Modules\n",
    "import Gnowee\n",
    "import ObjectiveFunctions as of\n",
    "import OptiPlot as op\n",
    "from GnoweeHeuristics import GnoweeHeuristics\n",
    "from GnoweeUtilities import Event\n",
    "\n",
    "# Select optimization problem type and associated parameters\n",
    "#optFunc = of.WeldedBeam_Obj\n",
    "#optFunc = of.PressureVessel_Obj\n",
    "#optFunc = of.SpeedReducer_Obj\n",
    "#optFunc = of.Spring_Obj\n",
    "optFunc = of.MI_Spring_Obj\n",
    "#optFunc = of.MI_PressureVessel_Obj\n",
    "#optFunc = of.Chemical_Process_Obj\n",
    "\n",
    "#optFunc = of.Ackley_Obj\n",
    "#optFunc = of.Shifted_Ackley_Obj\n",
    "#optFunc = of.DeJong_Obj\n",
    "#optFunc = of.Shifted_DeJong_Obj\n",
    "#optFunc = of.Easom_Obj\n",
    "#optFunc = of.Shifted_Easom_Obj\n",
    "#optFunc = of.Griewank_Obj\n",
    "#optFunc = of.Shifted_Griewank_Obj\n",
    "#optFunc = of.Rastrigin_Obj\n",
    "#optFunc = of.Shifted_Rastrigin_Obj\n",
    "#optFunc = of.Rosenbrock_Obj\n",
    "#optFunc = of.Shifted_Rosenbrock_Obj\n",
    "\n",
    "#optFunc = of.TSP_Obj\n",
    "\n",
    "# Set optimization settings\n",
    "gh.initSampling = 'lhc'\n",
    "gh.population = 25\n",
    "gh.alpha = 0.5\n",
    "gh.fracDiscovered = 0.2\n",
    "gh.fracElite = 0.2\n",
    "gh.fracLevy = 0.2\n",
    "gh.stallLimit = 225\n",
    "gh.scalingFactor = 10\n",
    "gh.maxFevals = 200000\n",
    "\n",
    "# Initialize variables\n",
    "maxIter = 100       # Number of algorithm iterations\n",
    "evalInterval = 500  # Fuction eval interval at which the fitness is sampled.  \n",
    "history = []        # List that contains the final timeline results from each optimization run \n",
    "\n",
    "# History of fitness vs function evals [Feval, Fit avg, Fit std, counter]\n",
    "fevalHistory = np.array([[i*evalInterval,0.0,0.0,0] for i in \\\n",
    "                            range(int(gh.maxFevals/evalInterval)+1)])\n",
    "\n",
    "# Run optimization\n",
    "for i in range(0,maxIter,1):\n",
    "    print \"Run #{}\".format(i)\n",
    "    optParams = of.Get_Params(optFunc, 'Gnowee', dimension=7)\n",
    "    gh = GnoweeHeuristics(optimalFitness=optParams.o)\n",
    "    (timeline) = Gnowee.main(optFunc, optParams.lb, optParams.ub, optParams.vt, gh, \n",
    "                             discreteVals=optParams.dv)\n",
    "\n",
    "    # Save final timeline data for future processing\n",
    "    minGen = min(timeline, key=attrgetter('fitness'))\n",
    "    history.append(Event(minGen.generation,minGen.evaluations,minGen.fitness,\n",
    "                             minGen.design))\n",
    "\n",
    "    # Update Fitness vs Feval History\n",
    "    k = 1 \n",
    "    \n",
    "    # Compute the average and standard deviation using a recurrence relation\n",
    "    for j in range(0, len(fevalHistory),1):\n",
    "        while timeline[k].evaluations < fevalHistory[j,0] and k+1 < len(timeline):  \n",
    "            k += 1\n",
    "        if k+1 == len(timeline) and timeline[k].evaluations < fevalHistory[j, 0]:\n",
    "            # Initialize the array on the first run\n",
    "            if fevalHistory[j, 3] == 0:\n",
    "                fevalHistory[j, 1] = timeline[k].fitness\n",
    "                fevalHistory[j, 2] = 0.0\n",
    "                fevalHistory[j, 3] += 1\n",
    "            else:\n",
    "                oldMean = fevalHistory[j,1]\n",
    "                fevalHistory[j, 3] += 1\n",
    "                fevalHistory[j, 1]=fevalHistory[j, 1]\\\n",
    "                                 +(timeline[k].fitness-fevalHistory[j,1])/fevalHistory[j,3]\n",
    "                fevalHistory[j, 2] = fevalHistory[j, 2] \\\n",
    "                                 +(timeline[k].fitness-oldMean)*(timeline[k].fitness \\\n",
    "                                                                 -fevalHistory[j,1])                \n",
    "            break\n",
    "        else:\n",
    "            # Initialize the array on the first run\n",
    "            if fevalHistory[j, 3] == 0:\n",
    "                fevalHistory[j, 1] = timeline[k-1].fitness\n",
    "                fevalHistory[j, 2] = 0.0\n",
    "                fevalHistory[j, 3] += 1\n",
    "            else:    \n",
    "                oldMean = fevalHistory[j,1]\n",
    "                fevalHistory[j, 3] += 1\n",
    "                fevalHistory[j, 1] = fevalHistory[j,1]+(timeline[k-1].fitness \\\n",
    "                                     -fevalHistory[j,1])/fevalHistory[j,3]\n",
    "                fevalHistory[j, 2] = fevalHistory[j,2]+(timeline[k-1].fitness \\\n",
    "                                     -oldMean)*(timeline[k-1].fitness-fevalHistory[j,1])\n",
    "            \n",
    "    #op.Plot_Feval_Hist(data=fevalHistory)\n",
    "    \n",
    "# Calculate averages and standard deviations\n",
    "tmp = []\n",
    "for i in range(len(history[-1].design)):\n",
    "    if optFunc.__name__ != \"TSP_Obj\":\n",
    "        tmp.append(sum(c.design[i] for c in history)/float(len(history)))\n",
    "averages = Event(sum(c.generation for c in history)/float(len(history)),\n",
    "                     sum(c.evaluations for c in history)/float(len(history)),\n",
    "                     sum(c.fitness for c in history)/float(len(history)),tmp)\n",
    "\n",
    "tmp=[]\n",
    "if maxIter > 1:\n",
    "    for i in range(len(history[-1].design)):\n",
    "        if optFunc.__name__ != \"TSP_Obj\":\n",
    "            tmp.append(m.sqrt(sum([(c.design[i]-averages.design[i])**2 for c in history]) \\\n",
    "                              /(len(history) - 1)))\n",
    "    stdDev = Event(m.sqrt(sum([(c.generation-averages.generation)**2 for c in history]) \\\n",
    "                               /(len(history) - 1)),\n",
    "                        m.sqrt(sum([(c.evaluations- averages.evaluations)**2 for c in history]) \\\n",
    "                               /(len(history) - 1)),\n",
    "                        m.sqrt(sum([(c.fitness - averages.fitness)**2 for c in history]) \\\n",
    "                               /(len(history) - 1)),tmp)\n",
    "else:\n",
    "    tmp = np.zeros(len(history[-1].design))\n",
    "    stdDev = Event(0, 0, 0.0, tmp)\n",
    "\n",
    "# Trim empty feval histories \n",
    "if fevalHistory[-1,3 ] == 0:\n",
    "    fevalHistory = np.array([fevalHistory[tmp, :] for tmp in \\\n",
    "                            range(len(fevalHistory[0:(np.argmin(fevalHistory[:, 3]))]))])\n",
    "\n",
    "# Compute relative error (%Diff) for feval histories\n",
    "if gh.optimalFitness == 0.0:\n",
    "    fevalHistory[:, 1] = fevalHistory[:, 1]*100\n",
    "else:\n",
    "    fevalHistory[:, 1] = (fevalHistory[:, 1]-gh.optimalFitness)/gh.optimalFitness*100\n",
    "    fevalHistory[:, 1] = [cur if i >= 0 else 0 for cur in fevalHistory[:, 1]]\n",
    "\n",
    "# Compute standard deviation for feval histories\n",
    "for i in range(0, len(fevalHistory)):\n",
    "    if fevalHistory[i, 2] != 0.0:\n",
    "        fevalHistory[i, 2] = np.sqrt(fevalHistory[i, 2]/(fevalHistory[i, 3]-1))*100\n",
    "\n",
    "# Output average results to the user\n",
    "print \"\\nThe Average Optimized Solution for {}:\".format(optFunc.__name__)\n",
    "print \"================================\"\n",
    "print \"Design:\"\n",
    "for i in range(len(averages.design)):\n",
    "    print \"   var %d: %4.6f $\\mypm$ %4.5f \" %(i+1, averages.design[i], stdDev.design[i])\n",
    "print \"Fitness: %4.6f $\\mypm$ %4.5f \" %(averages.fitness, stdDev.fitness)\n",
    "print \"Funct Evals: %d $\\mypm$ %d \" %(averages.evaluations, stdDev.evaluations)\n",
    "print \"Generations: %3.1f $\\mypm$ %3.1f \"  %(averages.generation, stdDev.generation)\n",
    "if gh.optimalFitness == 0.0:\n",
    "    print \"The performance metric is %4.1f\" %(averages.fitness*(averages.evaluations \\\n",
    "                                                                +3*stdDev.evaluations))\n",
    "else:\n",
    "    print \"The performance metric is %4.1f\" %(abs((averages.fitness-gh.optimalFitness) \\\n",
    "                                                  /gh.optimalFitness) \\\n",
    "                                              *(averages.evaluations+3*stdDev.evaluations))\n",
    "\n",
    "#Determine the best values obtained\n",
    "best = min(history, key=attrgetter('fitness'))\n",
    "\n",
    "# Output best result to the user\n",
    "print \"\\nThe Best Optimized Solution for {}:\".format(optFunc.__name__)\n",
    "print \"================================\"\n",
    "print \"Design:\"\n",
    "for i in range(len(averages.design)):\n",
    "    print \"   var %d: %4.6f \" %(i+1,best.design[i])\n",
    "print \"Fitness: %4.6f \" %best.fitness\n",
    "print \"Funct Evals: %d \" %best.evaluations\n",
    "print \"Generations: %d \"  %best.generation\n",
    "if gh.optimalFitness == 0.0:\n",
    "    print \"The performance metric is %4.1f\" %(best.fitness*best.evaluations)\n",
    "else:\n",
    "    print \"The performance metric is %4.1f\" %(abs((best.fitness-gh.optimalFitness) \\\n",
    "                                                  /gh.optimalFitness)*best.evaluations)\n",
    "        \n",
    "#Plot the optimization process\n",
    "if  optFunc.__name__ != \"TSP_Obj\":\n",
    "    op.Plot_Vars(timeline, low_bounds=optParams.lb, up_bounds=optParams.ub, title=optParams.pt,\n",
    "                 label=optParams.l)\n",
    "fevals=[tmp.evaluations for tmp in history]\n",
    "if maxIter >1:\n",
    "    op.Plot_Hist(fevals,title=optParams.ht)\n",
    "op.Plot_Feval_Hist(data=fevalHistory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print 'np.array([',\n",
    "for i in range(0,len(fevalHistory)-1,1):\n",
    "    print '[',fevalHistory[i,0],',',fevalHistory[i,1],',',fevalHistory[i,2],',',fevalHistory[i,3],'],',\n",
    "print '[',fevalHistory[-1,0],',',fevalHistory[-1,1],',',fevalHistory[-1,2],',',fevalHistory[-1,3],']])'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.asarray(fevals)\n",
    "fevals_sa=np.array([5238,1559,2817,3526,3416,4152,2206,4245,3156,10541,4180,8432,8730,788,21581,33875,181,7497,10765,10356,13892,1464,11292,852,3102,14327,11751,10614,6644,5555,10032,11013,497,2561,12933,11375,518,16274,5350,548,11229,7942,2734,14784,2931,900,2321,5614,3524,4352,519,440,4724,2815,185,12976,1729,3880,3837,5816,8181,235,8843,464,516,5871,776,3091,1487,8701,2428,13321,1416,450,10528,10877,3704,15275,13844,1482,2233,12924,22809,1886,17178,3604,5780,7805,16553,16035,8262,2168,11495,4708,29899,270,3082,13516,6173,2082,3228,26509,10969,7620,7338,19709,3391,20966,3466,1664,5640,146,18900,1051,4302,12719,5008,1230,20339,4284,1077,10217,3022,2079,13399,8788,15191,8916,18181,2206,8424,13546,1853,6575,2497,10146,3416,3752,1215,617,4827,7514,1542,15413,623,13647,4351,8758,4714,565,8811,4506,1104,3203,910,2589,7751,853,13087,2690,11162,4630,11260,4641,2950,1806,1245,9654,218,5882,9724,4935,11808,3156,1541,240,6712,1495,8407,16436,11959,4825,1488,3310,5670,13924,14795,5077,7557,278,8377,1151,3725,23145,1540,19840,3423,7192,182,15090,1752,9963,27604,2140,2528,5210,11251,10318,14631,727,849,5221,1186,1777,5951,3280,9678,14095,16917,5966,7607,508,9909,1830,11126,22264,11875,12423,10171,467,1443,7163,1418,7074,2047,12614,13642,1480,467,13035,1808,4272,2849,1486,7382,2904,187,3764,8881,12350,8842,11332,13676,7266,7049,1100,4946,1259,2081,177,266,12580,7719,10423,1743,21977,11220,3780,3282,6753,7432,3801,845,3454,9555,4033,3042,2571,860,189,822,4179,12620,2740,8534,1933,6011,7410,4081,2548,12448,3761,1207,2242,16559,180,123,6490,21519,187,5040,1075,14680,2408,14243,11285,2096,801,7385,20283,1804,5565,168,177,1169,3047,10511,6920,11486,9818,1341,1224,6253,2155,8620,1482,16551,13096,1487,2894,10638,2610,1108,11471,6242,8306,18901,2745,235,11186,10598,6738,2463,1171,1158,3531,2557,20031,6640,1509,928,1072,1504,1416,8688,13121,11779,2819,4109,4981,12213,4446,9152,2518,3381,801,3973,9006,881,1490,4515,2453,2849,2799,6137,5850,387,8509,7797,9408,3129,1961,14542,16877,4387,1507,14145,14791,13986,1176,1523,10289,10404,10555,5804,14445,1843,611,2486,12849,1406,1424,1296,1354,11575,15491,6910,644,11406,201,15140,5246,12448,2117,4998,14934,8828,7058,3394,3100,10526,2932,2987,771,4281,4529,548,159,1763,1829,570,9929,6003,2602,1743,11276,1495,8218,2241,575,5392,3120,630,16880,13480,4797,3471,6937,4705,4550,12185,5786,3093,5426,5602,2783,2244,9728,17860,6228,4651,1162,478,6152,446,5676,2812,1727,2526,680,1175,2621,15396,7618,258,26964,205,6425,9067,3044,7175,567,8013,15140,10895,2389,5945,8057,1505,609,10301,183,9313,3649,19532,1580,12922,17984,8191,5101,10933,17647,2377,4775,15259,5170,9459,7996,4065,6290,3250,18144,7907,2439,1143,1194,5679,11949,1435,4723,24608,632,2588,1117,4014,6137,2011,2923,10183,1403,3766,4423,11525,8303,10472,11815,3106,17964,1247,2733,514,16436,8255,9979,495,10189,5637,8987,204,2510,9937,580,12268,14791,5330,228,3419,8556,11264,10912,16607,10947,10058,1165,13114,4435,2197,5680,4489,2068,504,2101,1484,3925,2251,1466,2114,6038,3517,1769,9388,22773,2037,4617,1689,1716,2406,181,3754,215,1125,15972,478,3321,13025,6010,2695,13233,4255,10434,3526,17869,748,4194,7953,4882,2401,1783,2121,1214,17426,2741,10939,10623,158,646,597,5114,13098,1463,3486,1241,4020,3263,19729,10982,834,1984,7154,2897,7695,8149,480,4840,500,13207,2809,4397,1158,12157,806,610,15135,397,2840,8636,1832,11215,1750,2916,8365,1524,2037,1543,1368,4420,7806,1467,3056,5773,4190,11963,848,1732,13152,15071,10848,12540,489,3179,11950,9816,1442,876,16878,3232,18647,3024,11423,1170,4044,1281,1717,3704,8525,7689,1632,10906,10947,1553,842,3410,19792,10223,10428,484,588,10499,4122,2483,2685,201,3430,8908,11617,782,5436,13070,7250,4390,15560,793,6455,13012,2167,3276,5096,5469,153,425,7912,1058,12555,191,211,4592,4207,268,10123,5342,4067,18088,1416,4310,16645,578,1604,9217,3514,13589,422,23209,6281,14466,2467,1101,3692,6371,18763,11239,3663,5406,491,3102,9377,11083,1215,223,213,203,472,6608,12531,14478,1625,1817,5587,480,6751,8796,837,1897,3833,5682,862,14714,3517,12947,469,15108,1057,859,5091,1212,1292,4126,11877,2040,20828,3469,2996,3679,6173,854,13293,2204,1882,396,1804,15969,2817,3770,603,5480,1105,2734,1978,2116,3566,834,3028,1612,9141,3403,1148,1494,2455,8944,2903,798,8604,1566,931,1209,4592,997,4891,1521,1929,853,7472,917,1405,812,10748,12374,9579,16117,150,1810,1845,515,208,5777,489,1530,4198,14846,2384,9130,2261,18337,1242,6522,3135,4007,811,829,5234,10452,3166,9221,3815,14020,9217,12777,267,3346,492,10482,3022,3599,7846,1114,1489,3825,1175,1378,5883,11869,12792,3466,2922,6499,8404,7497,17463,2560,10923,977,11696,4245,466,5411,12930,10598,5539,865,3881,855,3841,16362,3456,1497,5797,6821,802,894,2175,5318,2877,3614,14600,2038,3792,8653,189,18744,12735,8257,1597,18335,2827,3571,10583,137,2310,9460,3555,510,11058,2565,13065,6327,11542,2504,2734,3725,6767,22992,11720,4595,10179,3682,6393,4064,1485,11309,4344,769,19731,6463,5793,10974,1804,6870,479,7142,1760,10361,3408,3680,12037,8408,10443,1562,21544,528,13234,2703,10900,4909,3720,7411,3525,6944,8929,6152,8100,10009,15069,9047,1504,20073,2920,815,17845,2083,499,2512,9701,13120,10500,6136,13150,7606,4330,3294,12156,12576])\n",
    "print fevals_sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
